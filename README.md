# Pippy_Activityüêç

## Introduction üìù
Our purpose of intgrating LLM in Pippy-Activity is quite clear. Making co-pilot quite similar like github but on a much elementary level and easy to use for children. Python codes which LLM generate are based mainly for developers to understand beacause its trained on a data of codes of developers available on internet. There are chances that the code generated by these models may be difficult for kids to understand beacause many a times kids are unable to give structured and clear prompts. This results in hallucinations in our output.
## Which LLMs to use‚ùì
There are many FOSS LLM available in the market like **Gemini, codellama, Mistral, LLama, GPT2, Gemma, Bloom, Mixtral, LLama2 and much more.** Based on their performance and architecture we need to shortlist the LLM for code generation purpose.
While working with Gemini, Bloom, GPT2 I found they are great for general text generative tasks but not suitable for code generation purposes.
This is because
1. The models had many hallucinations while working on complex codes which involve good amount of logic.
2. Computational power consumption of these models is relatively high compared to other models for same tasks. This adds a lot of maintainance cost in future.
3. Difficulties in fine-tuning these models. Hence making it difficult for us to cater kids. 
