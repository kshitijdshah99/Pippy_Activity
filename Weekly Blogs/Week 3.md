# Progress till Nowüìà
Up until week 2, I had completed the implementation of a model that could create Python code for children while also correcting them as needed. Last week, I encountered a major difficulty with training and loading Large Language Models, prompting me to modify my strategy from fine-tuning to a RAG-based approach.

# Week 3
This week, I spent the most of my time looking for adequate pygame documentation that included all of the intricacies and functionality of the methods utilized in this Python module. When it comes to functional use cases, Pygame is a somewhat large Python package. This makes it useful for a wide range of tasks and activities.
Sugar's codebase is entirely composed of Python and Sugar GTK code, with Pygame serving as its basis. Recently developed Sugar activities are mostly designed with Pygame.

## So what exactly is RAG?
RAG stands for retrieval-augmented generation. To put it simply, LLMs are trained on current data, hence the models are frequently out of date with the latest market information. It is evident that current data is always being updated, thus to avoid data loss, LLMs are kept up to date utilizing the RAG technique. In the RAG approach, our model first checks the user's query. In our case, once the child's query has been processed, it first checks in the knowledge database or the context that we have provided to the model in the retrieved part. If an answer to the query is found there, the output is directly generated based on that context; otherwise, the LLM generates an answer based on the data on which it has been trained.
[This](https://arxiv.org/pdf/2005.11401) is the study article I read to better understand how it works. The RAG technique does not disrupt the routine operation of an LLM.

![](https://miro.medium.com/v2/resize:fit:1127/1*Jq9bEbitg1Pv4oASwEQwJg.png)
### How did I install the RAG? 
So, RAG is essentially a method that can be included into any LLM. It may be used with a variety of frameworks Langchain is one of the most common options. I used langchain to create one. In the langchain framework, I tested pypdf, a Python package for splitting, merging, cropping, and modifying PDF documents. This library assisted me in reading the pdf and extracting all of the relevant information. This material was then tokenized and used as context throughout the retrieval process.
The following link contains basic idea of how langchain is used to retrieve data [https://www.langchain.com/retrieval](https://www.langchain.com/retrieval).
There is a document available on this site which describes the usage of this framework.
## Dataset
This is the [document](https://github.com/kshitijdshah99/Pippy_Activity/blob/main/Pygame%20Documentation.pdf) I discovered on the internet. It's pretty descriptive, but I altered it to meet the requirements.

### This documentation covers several ideas, to summarize them:

1.**Basic principles** taught were pygame introduction, dealing with shapes, pictures, text, and drawing graphics primitives.

2.**Intermediate techniques** included playing music and constructing a graphic user interface (GUI).

3.**Advanced notions** include creating an app, a basic board game, or even tiles for it.

### Reasons why I chose this documentation‚ùì
1. It includes correct code samples.
The manual includes code snippets and examples for all of the basic to complex functions mentioned. This makes it easier for the LLM to create the appropriate output relating to the child's question.
2. Well-formatted data.
Everything in this handbook has been presented in an organized manner, allowing LLM to easily process the child's query and produce a proper response. This thorough manual strives to cover every feature of the Pygame library.

## Ouput
These tasks of code generations, corrrection and Pygame part has been successfully generated by our Llama models

#### Task 1- Generating python snippets and examples
![](https://github.com/kshitijdshah99/Pippy_Activity/blob/main/Output/Code%20generation%20and%20example.png)

#### Task 2- Code correction
![](https://github.com/kshitijdshah99/Pippy_Activity/blob/main/Output/Code%20Correction.png)

#### Task 3- Navigating Pygame basics 
![](https://github.com/kshitijdshah99/Pippy_Activity/blob/main/Output/Pygame%20Code.png)
##### Codellama output
![](https://github.com/kshitijdshah99/Pippy_Activity/blob/main/Output/pygame%20Codellama.png)
## Mistakes
While presenting my work to my mentors during our usual Monday meetings, they pointed out a code snippet that lacked correct indentation of Python scripts. They recommended me to conduct study on the topic. While studying, I discovered that this is a type of hallucination produced by the model itself. Yes, I tried several more user queries, but such an issue never occurred again.

# Summary
So with this, we are done implementing three functionalities. 
1. Generate Python code snippets
2. Correcting Python code
3. Pygame Basics
We implemented a RAG architecture in the LLM.

This resolves all GPU-related issues, including resource allocation and fine-tuning. The Pygame feature that I built this week comprises all of the frequently utilized capabilities.

# Plan for next weeküìù
GTK serves as the foundation for the Sugar codebase, hence I intend to add GTK code creation into our LLM next week. This would be done again using the RAG architecture. The GTK document would include the relevant scripts and functionalities.

Aside from GTK, I intend to manually develop one document in which the model will be able to produce pre-existing code for Sugar activities. This would provide children and developers with a general notion of how pygame and GTK are combined to build new Sugar activities.
