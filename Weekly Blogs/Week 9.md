# Progress till NowðŸ“ˆ
I am done with completing major part of the UI modification. I am also clear with major parts of the things with respect to integration. 

# Week 9
So this week I explored further ways with respect to integration. basically using APIs, deploying model on server and so on. I would like it to summrize it in this blog post for my freinds.
So I have made a LLM RAG architecture in my colab file obviously it's not feasible to run in on a server. 
### Step 1 
Convert the Colab file into a .py file with all the dependencies in a requirements.txt file. Using this you can make a LLM run locally on your VS code. Make sure you create a seperate environment for the same and list all the dependencies in 1 file reuirements.txt. Using the command given below you can install all the dependenies locally o your system.

pip install -r requirements.txt
